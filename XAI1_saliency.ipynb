{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u67zi7gS__Om"
   },
   "source": [
    "## XAI 1: Introduction to Saliency Maps with Captum\n",
    "\n",
    "Base example based on:\n",
    "\n",
    "*   https://captum.ai/tutorials/TorchVision_Interpret\n",
    "*   https://pytorch.org/tutorials/beginner/introyt/captumyt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdTFPHsZAEPQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "!pip install captum\n",
    "from captum.attr import IntegratedGradients, LayerGradCam, LayerAttribution\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSRm0NHrAfU6"
   },
   "source": [
    "Let's start out with a pretrained ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OumHPXOPAh3m"
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DyeJCytAiws"
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScZ44vAPA63X"
   },
   "source": [
    "Let's fetch the imagenet labels for interpretation of model, as well as an image to test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqKNbbEAA9OK"
   },
   "outputs": [],
   "source": [
    "# Imagenet labels\n",
    "!wget -P $HOME/.torch/models https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
    "\n",
    "labels_path = os.getenv(\"HOME\") + '/.torch/models/imagenet_class_index.json'\n",
    "with open(labels_path) as json_data:\n",
    "    idx_to_labels = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c59adgKbObwK"
   },
   "source": [
    "Let's implement the ImageNet transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NziPhSULBDHH"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    " transforms.Resize(256),\n",
    " transforms.CenterCrop(224),\n",
    " transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_normalize = transforms.Normalize(\n",
    "     mean=[0.485, 0.456, 0.406],\n",
    "     std=[0.229, 0.224, 0.225]\n",
    " )\n",
    "\n",
    "response = requests.get(\"https://image.freepik.com/free-photo/two-beautiful-puppies-cat-dog_58409-6024.jpg\")\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "display(img)\n",
    "\n",
    "transformed_img = transform(img)\n",
    "\n",
    "input = transform_normalize(transformed_img)\n",
    "input = input.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIKd_qqRHvri"
   },
   "source": [
    "Let's predict the class of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7OnzJ7YG9e_"
   },
   "outputs": [],
   "source": [
    "output = model(input)\n",
    "output = F.softmax(output, dim=1)\n",
    "prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "\n",
    "pred_label_idx.squeeze_()\n",
    "predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n",
    "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo6we2S1IIvv"
   },
   "source": [
    "## Let's take a look at the Integrated Gradients saliency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0K9mCzTHzwq"
   },
   "outputs": [],
   "source": [
    "integrated_gradients = IntegratedGradients(model)\n",
    "attributions_ig = integrated_gradients.attribute(input, target=pred_label_idx, n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bncs66dIUK1"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "default_cmap = LinearSegmentedColormap.from_list('custom blue',\n",
    "                                                 [(0, '#ffffff'),\n",
    "                                                  (0.25, '#000000'),\n",
    "                                                  (1, '#000000')], N=256)\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                             np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                             methods=[\"original_image\", \"heat_map\"],\n",
    "                             cmap=default_cmap,\n",
    "                             show_colorbar=True,\n",
    "                             signs=[\"all\", \"positive\"],\n",
    "                             outlier_perc=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCnIGRmwJc36"
   },
   "source": [
    "Next, we apply the same smoothing trick as in SmoothGrad -- in Captum, this is called a *noise tunnel*, and can be applied to any saliency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSUa3P68Idnz"
   },
   "outputs": [],
   "source": [
    "from captum.attr import NoiseTunnel\n",
    "\n",
    "noise_tunnel = NoiseTunnel(integrated_gradients)\n",
    "\n",
    "attributions_ig_nt = noise_tunnel.attribute(input, nt_samples=10, nt_type='smoothgrad_sq', target=pred_label_idx)\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"positive\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BgNnN8AKne0"
   },
   "source": [
    "## Next, we add the GradCam saliency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpbuUIg-Jq8V"
   },
   "outputs": [],
   "source": [
    "layer_gradcam = LayerGradCam(model, model.layer4[1].conv2)\n",
    "attributions_lgc = layer_gradcam.attribute(input, target=pred_label_idx)\n",
    "\n",
    "_ = viz.visualize_image_attr(attributions_lgc[0].cpu().permute(1,2,0).detach().numpy(),\n",
    "                             sign=\"all\",\n",
    "                             title=\"Layer 4 Block 1 Conv 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNHrKnzJLX7g"
   },
   "source": [
    "Upsample GradCam saliency map to original image domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYCv7m-FK8nz"
   },
   "outputs": [],
   "source": [
    "upsamp_attr_lgc = LayerAttribution.interpolate(attributions_lgc, input.shape[2:], 'bilinear')\n",
    "\n",
    "print(attributions_lgc.shape)\n",
    "print(upsamp_attr_lgc.shape)\n",
    "print(input.shape)\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(upsamp_attr_lgc[0].cpu().permute(1,2,0).detach().numpy(),\n",
    "                                      transformed_img.permute(1,2,0).numpy(),\n",
    "                                      [\"original_image\",\"blended_heat_map\",\"masked_image\"],\n",
    "                                      [\"all\",\"positive\",\"positive\"],\n",
    "                                      show_colorbar=True,\n",
    "                                      titles=[\"Original\", \"Positive Attribution\", \"Masked\"],\n",
    "                                      fig_size=(18, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akSKGRjTOtUc"
   },
   "source": [
    "# Exercise!\n",
    "Pick among the following exercises, and make sure that you get well acquainted with the different types of saliency maps\n",
    "\n",
    "1.   Try out different saliency methods implemented in Captum -- do they tell the same story? Try also with your own test images. Also check out some that we didn't discuss -- how do they differ from the ones we have gone through in class?\n",
    "2.   In the Colab Notebook on shortcut learning, try to insert a synthetic shortcut in the simple MNIST classifier by retraining it on data that is corrupted, e.g. by adding a number of consequtive white pixels that corresponds to the ground truth integer. Can you get the model to learn a shortcut? Can you detect it using saliency maps?\n",
    "3.   Can you reproduce the example where saliency maps are left untouched by adversarial attacks? Check out e.g. the torchattacks *toolbox*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Khqe45ZzLi8H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
